{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da91d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2092cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892a4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image using 'imread' specifying the path to image\n",
    "img = cv2.imread('D:\\\\Data Science by SRK\\\\Deep Learning\\\\images\\\\tiger.JPG',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f696e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 10  33 119]\n",
      "  [  0  21 107]\n",
      "  [ 18  38 126]\n",
      "  ...\n",
      "  [ 12  27  73]\n",
      "  [ 16  32  75]\n",
      "  [ 24  40  83]]\n",
      "\n",
      " [[ 12  35 121]\n",
      "  [  0  19 105]\n",
      "  [ 11  31 119]\n",
      "  ...\n",
      "  [ 24  39  85]\n",
      "  [ 12  27  73]\n",
      "  [  4  20  63]]\n",
      "\n",
      " [[ 18  39 124]\n",
      "  [  0  20 105]\n",
      "  [  4  24 111]\n",
      "  ...\n",
      "  [ 11  25  73]\n",
      "  [  9  23  71]\n",
      "  [ 14  29  75]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[215 214 223]\n",
      "  [215 214 223]\n",
      "  [216 215 224]\n",
      "  ...\n",
      "  [197 218 226]\n",
      "  [196 218 230]\n",
      "  [191 212 227]]\n",
      "\n",
      " [[215 214 223]\n",
      "  [216 215 224]\n",
      "  [216 215 224]\n",
      "  ...\n",
      "  [195 216 224]\n",
      "  [197 219 231]\n",
      "  [190 212 224]]\n",
      "\n",
      " [[214 213 222]\n",
      "  [214 213 222]\n",
      "  [215 214 223]\n",
      "  ...\n",
      "  [196 217 225]\n",
      "  [200 222 233]\n",
      "  [194 216 228]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533216a",
   "metadata": {},
   "source": [
    "Shape gives the dimensions of the image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8d5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 480, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape\n",
    "\n",
    "# The 3D dimensions are 720 pixels in height *(multiply by) 480 pixels width\n",
    "# 3 means that there are 3 components(combination of RGB colors) that make up image \n",
    "# (3 means the image is 3D array ehich means the image is colourful image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327618cb",
   "metadata": {},
   "source": [
    "# Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73bdc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display our image variable, we use 'imshow' function\n",
    "# The 1st parameter in imshow function is the title shown on image window\n",
    "# The 2nd parameter in imshow function will is the image loaded variable(i.e here img)\n",
    "\n",
    "cv2.imshow('tiger',img)\n",
    "\n",
    "\n",
    "# 'waitKey()' function allows us to input information when a image window is open \n",
    "    # if we give waitkey() function without parameter then it will wait the image window untill we press any key on keyboard\n",
    "    # if we give waitkey(2000) function with parameter then it will wait the image window upto the given time will not complete(here time is in miliseconds)\n",
    "    \n",
    "cv2.waitKey(2000)\n",
    "\n",
    "\n",
    "# destroyAllWindows() function closes all open windows\n",
    "# If we not write destroyAllWindows() function, then our program can be hang\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f586e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread('D:\\\\Data Science by SRK\\\\Deep Learning\\\\images\\\\tiger.JPG',1)\n",
    "#cv2.imshow('tiger', img)\n",
    "#cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38a0ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'imwrite()' used to specificing the file name and save the image in current working directory\n",
    "\n",
    "cv2.imwrite('tiger_b_w.jpg', img)   # It will save the image in current working directory with the name as 'tiger_b_w.jpg'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc450838",
   "metadata": {},
   "source": [
    "# Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45076276",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('D:\\\\Data Science by SRK\\\\Deep Learning\\\\images\\\\tiger.JPG')\n",
    "\n",
    "resized_image = cv2.resize(img,(400,400))  # ---> here the color image will resized into the given size of image.\n",
    "\n",
    "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)   # here the color image will convert (or display) into the black & white image which will be the 2D-array\n",
    "\n",
    "cv2.imshow('Tiger Image', gray)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Note:-\n",
    "       # This shell will continouely run untill we externally exit the image window(means we have press the exit(any key) to exit from the image window then only this shell will stop running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28da0e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[0]*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b794d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[1]*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919c8c0",
   "metadata": {},
   "source": [
    "# Face Detection using HAAR Cascade Classifier\n",
    "\n",
    "     Note :- \n",
    "               To use the HAAR Casacde Classifier files we have to first download that files and save them into the current                working directory otherwise it will not work(it will give error). \n",
    "           \n",
    "                means  eg.  - To use the 'haarcascade_frontalface_default.xml' & 'haarcascade_eye.xml' files to detect                      face(s) and eye(s) resp. Firstly we have to download them and save them into the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2072293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we point OpenCV'S CascadeClassifier function to where our classifier(in .xml file format) is stored\n",
    "# The CascadeClassifier will stores all types of sketches to detection of related objects from the images\n",
    "    # The HAAR Cascade Classifier is developed by the software developer which stores the stores the all types sketches in it in the .xml file format \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  # Here this will load the frontalface i.e. face related sketeches on the machine to detect the face(s) from the given image\n",
    "\n",
    "# Load our image then convert it into the grayscale image(means into black & white image)\n",
    "image = cv2.imread('D:\\\\Data Science by SRK\\\\Deep Learning\\\\images\\\\tiger.JPG')\n",
    "# image = cv2.resize(image,(400,400))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "### Tuning Cascade Classifiers - detectMultiScale(input image, **Scale Factor**, **Min Neighbors**) \\\n",
    "faces = face_classifier.detectMultiScale(gray, 1.05, 5)   # ---> Here, this function is used to detect the face from the given input image by reducing the size of image each time(i.e. here it will reduce the size by 5%(1.05) each time)\n",
    "                                                              # and also this function will not check the face in exact location of face in image it will try to match the features of face with all the given no. of neighbors in image\n",
    "                                                              # (i.e. it will try to match the features(steches) with the given no. of neighbors pixels in the given image)\n",
    " \n",
    "\n",
    "\n",
    "# **Scale Factor** - It specifies how much we reduce the image size each time we scale(i.e. means while matching the steches(features) how much the size of image we reduce to detect the face in the image)\n",
    "                    # that means to detect the face from the image the machine will not check line by line that the features from cascade classifier are matching with image small part(i.e.pixel) or not that means it will match the features by reducing overall size of image each time untill the face detection.\n",
    "    # eg. in face detection we typically use 1.3. This means we reduce the image size by 30% each time of it's total size.\n",
    "    # The smaller value of scale factor like 1.05 will take longer time to compute(to give result), it will give high accuracy(increse the rate of detection).\n",
    "    \n",
    "\n",
    "# **Min Neighbors** - It speciefies the no. of neighbors each potential window should have in order to consider it a positive detection(i.e. means while detecting the face in the image the machine will check the face in the given no. of neighbors from the face detected location in the image)\n",
    "# typically we use 3-6 no. of neighbors.\n",
    "# It acts as sensitivity setting, if no. of neighbors are less then it will sometimes detect multiples faces over a single face.\n",
    "                                # if no. of neighbors are high then it will ensure less false positives(less error), but you may miss some faces to detect from image.\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1767d1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  76 244 244]]\n"
     ]
    }
   ],
   "source": [
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3714edf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:31: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_9088\\2338786775.py:31: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "# we point OpenCV'S CascadeClassifier function to where our classifier(in .xml file format) is stored\n",
    "# The CascadeClassifier will stores all types of sketches to detection of related objects from the images\n",
    "    # The HAAR Cascade Classifier is developed by the software developer which stores the stores the all types sketches in it in the .xml file format \n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  # Here this will load the frontalface i.e. face related sketeches on the machine to detect the face(s) from the given image\n",
    "\n",
    "# Load our image then convert it into the grayscale image(means into black & white image)\n",
    "image = cv2.imread('D:\\\\Data Science by SRK\\\\Deep Learning\\\\images\\\\tiger.JPG')\n",
    "image = cv2.resize(image,(400,400))\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "### Tuning Cascade Classifiers - detectMultiScale(input image, **Scale Factor**, **Min Neighbors**) \\\n",
    "faces = face_classifier.detectMultiScale(gray, 1.05, 5)   # ---> Here, this function is used to detect the face from the given input image by reducing the size of image each time(i.e. here it will reduce the size by 5%(1.05) each time)\n",
    "                                                              # and also this function will not check the face in exact location of face in image it will try to match the features of face with all the given no. of neighbors in image\n",
    "                                                              # (i.e. it will try to match the features(steches) with the given no. of neighbors pixels in the given image)\n",
    " \n",
    "\n",
    "\n",
    "# **Scale Factor** - It specifies how much we reduce the image size each time we scale(i.e. means while matching the steches(features) how much the size of image we reduce to detect the face in the image)\n",
    "                    # that means to detect the face from the image the machine will not check line by line that the features from cascade classifier are matching with image small part(i.e.pixel) or not that means it will match the features by reducing overall size of image each time untill the face detection.\n",
    "    # eg. in face detection we typically use 1.3. This means we reduce the image size by 30% each time of it's total size.\n",
    "    # The smaller value of scale factor like 1.05 will take longer time to compute(to give result), it will give high accuracy(increse the rate of detection).\n",
    "    \n",
    "\n",
    "# **Min Neighbors** - It speciefies the no. of neighbors each potential window should have in order to consider it a positive detection(i.e. means while detecting the face in the image the machine will check the face in the given no. of neighbors from the face detected location in the image)\n",
    "# typically we use 3-6 no. of neighbors.\n",
    "# It acts as sensitivity setting, if no. of neighbors are less then it will sometimes detect multiples faces over a single face.\n",
    "                                # if no. of neighbors are high then it will ensure less false positives(less error), but you may miss some faces to detect from image.\n",
    "    \n",
    "\n",
    "# When no faces are detected, then face_classifier returns an empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "    \n",
    "# We iterate through our faces array and draw a rectangle over each face in faces from images\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,100), 1)   # It will draw the rectangle box on the detected faces from image\n",
    "    \n",
    "cv2.imshow('Face Detection', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f238b",
   "metadata": {},
   "source": [
    "# Face & Eye Detection using HAAR Cascade Classifiers in Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4973037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_9088\\31636521.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')  # Here this will load the eye i.e.eye related sketeches on the machine to detect the eye(s) from the given image\n",
    "\n",
    "img = cv2.imread('D:\\\\Data Science by SRK\\\\Deep Learning\\\\images\\\\sky.webp')\n",
    "resized_img = cv2.resize(img,(720,720))\n",
    "gray = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no face is detected , then face_classifier will returns an empty tuple\n",
    "if faces is ():\n",
    "    print(\"No face found...\")\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(resized_img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = resized_img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "cv2.imshow('img',resized_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627e68c",
   "metadata": {},
   "source": [
    "# Capturing a video by Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdd7a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some Face Recognition(detection) with the webcam(live video)\n",
    "\n",
    "import cv2\n",
    "video = cv2.VideoCapture(0)  # Here, 0 means webcam\n",
    "\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('Video', gray)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab980ccf",
   "metadata": {},
   "source": [
    "# Face & Eye Detection using HAAR Cascade Classifiers in Webcam(live Video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269071a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that will do the face detection in webcam\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray,1.05,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(resized_img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.3, 3)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    return frame\n",
    "\n",
    "# Doing some face recognition with webcame\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray,frame)\n",
    "    cv2.imshow('Video', canvas)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c117f",
   "metadata": {},
   "source": [
    "# Pedistrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0770454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Create our body classifier\n",
    "body_classifier = cv2.CascadeClassifier('haarcascade_fullbody.xml')   # Here this will load the human body related sketeches on the machine to detect the human bodies from the given video(multiple images)\n",
    "\n",
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('walking.avi')    # Here this will load the already recorded video on the machine to detect the human bodies.\n",
    "\n",
    "# loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    # Read first frame\n",
    "    check, frame = cap.read()    # It will capture the first frame from the video and forward it to check(match) the sketches of cars with it. (and using while loop this will continuely cature frame untill video ends.)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Pass frame to our body classifier\n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n",
    "    \n",
    "    # Extract bounding boxes for any bodies indentified\n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,255), 2)\n",
    "        cv2.imshow('Podestrians', frame)\n",
    "        \n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba9dbc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Read first frame\u001b[39;00m\n\u001b[0;32m     17\u001b[0m check, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 18\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Pass frame to car(s) classifier\u001b[39;00m\n\u001b[0;32m     21\u001b[0m cars \u001b[38;5;241m=\u001b[39m car_classifier\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray, \u001b[38;5;241m1.4\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Create our body classifier \n",
    "car_classifier = cv2.CascadeClassifier('haarcascade_car.xml')   # Here this will load the car related sketeches on the machine to detect the car(s) from the given video(multiple images)\n",
    "\n",
    "#Initiate video capture for video file\n",
    "cap = cv2.VideoCapture('cars.avi')  # Here this will load the already recorded video on the machine to detect the car(s).\n",
    "\n",
    "\n",
    "# loop once video is successfully loaded\n",
    "while cap.isOpened():\n",
    "    \n",
    "    time.sleep(0.05)   # This will make the speed of video slow as per given value in 'sleep()' function\n",
    "    \n",
    "    # Read first frame\n",
    "    check, frame = cap.read()     # It will capture the first frame from the video and forward it to check(match) the sketches of cars with it. (and using while loop this will continuely capture frame untill video ends.)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Pass frame to car(s) classifier\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Extract bounding boxes for any car(s) indentified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,255), 2)\n",
    "        cv2.imshow('Cars', frame)\n",
    "        \n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb830b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
